{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "PizzaNet.ipynb",
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "566575cbf59c445798741d8d37f3f5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f06b6a6e8f2244b9b91913c94f7e4f96",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_901841aeb7d84c7fb4932f1f835748d4",
              "IPY_MODEL_20671a5b236a40c7a445b7fdae3c3dc3"
            ]
          }
        },
        "f06b6a6e8f2244b9b91913c94f7e4f96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "901841aeb7d84c7fb4932f1f835748d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_209be975f5ef4824a8be738f8d7a2e61",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1500,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfb9e9b5b4934fbe9060c6d1ccbcb7c5"
          }
        },
        "20671a5b236a40c7a445b7fdae3c3dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e04c51c9c1a84cc58073ef3eabf163f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1500/1500 [00:06&lt;00:00, 230.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_582d82e3e1044249b11cd58b1c22eaa8"
          }
        },
        "209be975f5ef4824a8be738f8d7a2e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfb9e9b5b4934fbe9060c6d1ccbcb7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e04c51c9c1a84cc58073ef3eabf163f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "582d82e3e1044249b11cd58b1c22eaa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sicvcahb1Psu"
      },
      "source": [
        "# Team Give Me Pizza\n",
        "\n",
        "## Pizza Project\n",
        "\n",
        "* Adam Sayre\n",
        "* Chenxi Lu\n",
        "* Lina Sheremet\n",
        "* Scott Robertson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mA349DB3baY",
        "outputId": "65c80bf0-a2b2-42d6-c035-a86c55a3d24d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords') "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4eoja5k1Psu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b56c79-58d4-4a1c-c01e-96a7ffbf9cb6"
      },
      "source": [
        "# This tells matplotlib not to try opening a new window for each plot.\n",
        "%matplotlib inline\n",
        "\n",
        "# Import a bunch of libraries.\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# General libraries.\n",
        "import re\n",
        "\n",
        "# SK-learn libraries for learning.\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# SK-learn libraries for evaluation.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# SK-learn libraries for feature extraction from text.\n",
        "from sklearn.feature_extraction.text import *\n",
        "\n",
        "import nltk\n",
        "\n",
        "# for preprocessors\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from scipy.sparse import coo_matrix, hstack\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "from sklearn.ensemble import AdaBoostClassifier \n",
        "\n",
        "import sys, os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn import metrics\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "import warnings\n",
        "warnings.filterwarnings(action='once')\n",
        "import pickle\n",
        "import shutil"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zn90uCBE2sPc",
        "outputId": "ab21c7b1-df73-4f87-f489-7027ee5da694"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-9mNU681Psv",
        "outputId": "66562ec8-ab08-4cfd-8729-60672adc9ce1"
      },
      "source": [
        "# Set the randomizer seed so results are the same each time.\n",
        "np.random.seed(0)\n",
        "\n",
        "input_data = pd.read_json('/content/drive/My Drive/train.json')\n",
        "input_data.shape\n",
        "\n",
        "input_data = input_data.sample(frac=1)\n",
        "\n",
        "dev_data = input_data[0:1347]\n",
        "train_data = input_data[1347:]\n",
        "\n",
        "print('Train data shape: ', train_data.shape)\n",
        "print('Dev data shape:', dev_data.shape)\n",
        "\n",
        "train_labels = train_data['requester_received_pizza']\n",
        "dev_labels = dev_data['requester_received_pizza']\n",
        "\n",
        "print('Train labels shape: ', train_labels.shape)\n",
        "print('Dev labels shape:', dev_labels.shape)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4040, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "stream",
          "text": [
            "Train data shape:  (2693, 32)\n",
            "Dev data shape: (1347, 32)\n",
            "Train labels shape:  (2693,)\n",
            "Dev labels shape: (1347,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCj4yZWo_q8T",
        "outputId": "5ea508e2-2a56-4bac-8b46-53f4dbbbc2e4"
      },
      "source": [
        "#################################################\n",
        "# One hot encoding of True / False\n",
        "boo = list(train_data.index)\n",
        "onehot_col_train = []\n",
        "for i in range(len(boo)):\n",
        "  x = train_data[i:i+1]\n",
        "  if x[\"requester_received_pizza\"][boo[i]] == True:\n",
        "    onehot_col_train.append(1)\n",
        "  else:\n",
        "    onehot_col_train.append(0)\n",
        "\n",
        "boo2 = list(dev_data.index)\n",
        "onehot_col_dev = []\n",
        "for i in range(len(boo2)):\n",
        "  x = dev_data[i:i+1]\n",
        "  if x[\"requester_received_pizza\"][boo2[i]] == True:\n",
        "    onehot_col_dev.append(1)\n",
        "  else:\n",
        "    onehot_col_dev.append(0)\n",
        "#################################################\n",
        "\n",
        "# Add encoded True / False\n",
        "train_data[\"encoding\"] = onehot_col_train\n",
        "# Add encoded True / False\n",
        "dev_data[\"encoding\"] = onehot_col_dev\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKWepun25IaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8eb2c0f-be68-4377-981c-06f63b160685"
      },
      "source": [
        "# Download the pretrained weights for bert base. \n",
        "!wget -nv --show-progress -O data/uncased_L-12_H-768_A-12.zip \\\n",
        "        https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!wget -nv --show-progress  -O data/cased_L-12_H-768_A-12.zip \\\n",
        "        https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
        "# unzip weights & conifg and remove the original zip\n",
        "!unzip -d data/ data/cased_L-12_H-768_A-12.zip && rm data/cased_L-12_H-768_A-12.zip   \n",
        "!unzip -d data/ data/uncased_L-12_H-768_A-12.zip && rm data/uncased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data/uncased_L-12_H-768_A-12.zip: No such file or directory\n",
            "data/cased_L-12_H-768_A-12.zip: No such file or directory\n",
            "unzip:  cannot find or open data/cased_L-12_H-768_A-12.zip, data/cased_L-12_H-768_A-12.zip.zip or data/cased_L-12_H-768_A-12.zip.ZIP.\n",
            "unzip:  cannot find or open data/uncased_L-12_H-768_A-12.zip, data/uncased_L-12_H-768_A-12.zip.zip or data/uncased_L-12_H-768_A-12.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjGYyEU-5IaO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac44d17-d3a5-4bcb-87c1-03b6c9bdd5e9"
      },
      "source": [
        "pip install torchvision"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.8.1+cu101)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.7.0->torchvision) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fn7p9H05IaO"
      },
      "source": [
        "# Let's activate CUDA for GPU based operations\n",
        "device=torch.device('cuda')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciaI7JyR5IaO"
      },
      "source": [
        "# In bert we need all inputs to have the same length, we will use the first 220 characters. \n",
        "MAX_SEQUENCE_LENGTH = 220\n",
        "SEED = 1234\n",
        "# We shall run a single epoch (ie. one pass over the data)\n",
        "EPOCHS = 1\n",
        "# PATH = '.'#'/root/v2/week06/hw' # /root/v2/week06/hw\"\n",
        "# DATA_DIR = os.path.join(PATH, \"data\")\n",
        "# WORK_DIR = os.path.join(PATH, \"workingdir\")\n",
        "\n",
        "# Validation and training sizes are here. \n",
        "train_size= 1000\n",
        "valid_size= 500"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qVOat0s5IaO"
      },
      "source": [
        "# os.listdir(DATA_DIR)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlJwNo7c5IaO"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "from transformers import BertModel, BertConfig, BertTokenizer, BertForSequenceClassification\n",
        "from transformers import AdamW as BertAdam"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVJY3Jie5IaO"
      },
      "source": [
        "%%capture\n",
        "bert_config = BertConfig()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D-_y5sl5IaO"
      },
      "source": [
        "def convert_lines(example, max_seq_length,tokenizer):\n",
        "    max_seq_length -=2\n",
        "    all_tokens = []\n",
        "    longer = 0\n",
        "    for text in tqdm_notebook(example):\n",
        "        tokens_a = tokenizer.tokenize(text)\n",
        "        if len(tokens_a)>max_seq_length:\n",
        "            tokens_a = tokens_a[:max_seq_length]\n",
        "            longer += 1\n",
        "        one_token = tokenizer.convert_tokens_to_ids([\"[CLS]\"]+tokens_a+[\"[SEP]\"])+[0] * (max_seq_length - len(tokens_a))\n",
        "        all_tokens.append(one_token)\n",
        "    print(longer)\n",
        "    return np.array(all_tokens)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUgenDn65IaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151,
          "referenced_widgets": [
            "566575cbf59c445798741d8d37f3f5f9",
            "f06b6a6e8f2244b9b91913c94f7e4f96",
            "901841aeb7d84c7fb4932f1f835748d4",
            "20671a5b236a40c7a445b7fdae3c3dc3",
            "209be975f5ef4824a8be738f8d7a2e61",
            "cfb9e9b5b4934fbe9060c6d1ccbcb7c5",
            "e04c51c9c1a84cc58073ef3eabf163f6",
            "582d82e3e1044249b11cd58b1c22eaa8"
          ]
        },
        "outputId": "ccf55361-a659-4267-dc51-b1864e1329aa"
      },
      "source": [
        "# %%time\n",
        "# tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, cache_dir=None,do_lower_case=True)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "train_all = train_data.sample(train_size+valid_size,random_state=SEED)\n",
        "print('loaded %d records' % len(train_all))\n",
        "\n",
        "# Make sure all comment_text values are strings\n",
        "train_all['request_text_edit_aware'] = train_all['request_text_edit_aware'].astype(str) \n",
        "\n",
        "sequences = convert_lines(train_all[\"request_text_edit_aware\"].fillna(\"DUMMY_VALUE\"),MAX_SEQUENCE_LENGTH,tokenizer)\n",
        "train_all=train_all.fillna(0)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loaded 1500 records\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "566575cbf59c445798741d8d37f3f5f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkD02Rx15IaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8e54f563-f40d-4631-d462-35adada3a832"
      },
      "source": [
        "train_all[[\"request_text_edit_aware\", 'encoding']].head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>request_text_edit_aware</th>\n",
              "      <th>encoding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>611</th>\n",
              "      <td>We just moved to a completely unfamiliar area,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>My alarm did not go off before work this after...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3271</th>\n",
              "      <td>hey, my sister just turned 15 and her birthday...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>Hello fellow pizza enthusiasts, it's been a ro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3297</th>\n",
              "      <td>I'm a student, and my fridge is empty. I would...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                request_text_edit_aware  encoding\n",
              "611   We just moved to a completely unfamiliar area,...         1\n",
              "1387  My alarm did not go off before work this after...         0\n",
              "3271  hey, my sister just turned 15 and her birthday...         0\n",
              "459   Hello fellow pizza enthusiasts, it's been a ro...         1\n",
              "3297  I'm a student, and my fridge is empty. I would...         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYe4pZmI5IaP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7527d843-7af3-46d2-8613-95d38fa853e9"
      },
      "source": [
        "text = 'Hi, I would like as many pizzas as possssssible please.'\n",
        "tokens = tokenizer.tokenize(text)\n",
        "' '.join(tokens)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hi , i would like as many pizza ##s as po ##ss ##ss ##ssi ##ble please .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqQ1tuUK5IaP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5489d6e5-0fcb-4b05-ac93-28163706247b"
      },
      "source": [
        "tokens = [\"[CLS]\"] + tokens + [\"[SEP]\"]\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "' '.join(map(str, input_ids))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'101 7632 1010 1045 2052 2066 2004 2116 10733 2015 2004 13433 4757 4757 18719 3468 3531 1012 102'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np-8uL-25IaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08aecf2-b8d0-4f79-de81-622820fb5b3f"
      },
      "source": [
        "# put input on gpu and make prediction\n",
        "bert = BertForSequenceClassification.from_pretrained('bert-base-uncased').cuda()\n",
        "# bert = BertModel.from_pretrained(WORK_DIR).cuda()\n",
        "bert_output = bert(torch.tensor([input_ids])).cuda()\n",
        "\n",
        "print('Sentence tokens {}'.format(tokens))\n",
        "print('Number of tokens {}'.format(len(tokens)))\n",
        "print('Tensor shapes : {}'.format([b.cpu().detach().numpy().shape for b in bert_output[0]]))\n",
        "print('Number of torch tensors : {}'.format(len(bert_output[0])))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence tokens ['[CLS]', 'hi', ',', 'i', 'would', 'like', 'as', 'many', 'pizza', '##s', 'as', 'po', '##ss', '##ss', '##ssi', '##ble', 'please', '.', '[SEP]']\n",
            "Number of tokens 19\n",
            "Tensor shapes : [(2,)]\n",
            "Number of torch tensors : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08cVFSzX5IaP"
      },
      "source": [
        "train_all['encoding']=(train_all['encoding']>=0.5).astype(float)\n",
        "# Training data - sentences\n",
        "X = sequences[:train_size] \n",
        "# Target - the toxicity. \n",
        "y = train_all[['requester_received_pizza']].values[:train_size]\n",
        "X_val = sequences[train_size:]                \n",
        "y_val = train_all[['requester_received_pizza']].values[train_size:]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1yuXnYw5IaP"
      },
      "source": [
        "test_df=train_all.tail(valid_size).copy()\n",
        "train_df=train_all.head(train_size)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7q2_cP_5IaP"
      },
      "source": [
        "# Training data creations\n",
        "train_dataset = torch.utils.data.TensorDataset(torch.tensor(X,dtype=torch.long), torch.tensor(y,dtype=torch.float))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4fS0CRf5IaP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "177be1ca-07d5-402d-da9e-2ef9d39447e8"
      },
      "source": [
        "SEED = 1234\n",
        "lr=2e-5\n",
        "batch_size = 32\n",
        "# batch_size=4\n",
        "accumulation_steps = 1\n",
        "# accumulation_steps = 8\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7faa0c2a3b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84otKenm5IaP"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',cache_dir=None,num_labels=1)\n",
        "model.zero_grad()\n",
        "model = model.to(device)\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSfMkYwX5IaP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "a0d28cbc-3349-451e-d7e7-bd3e2d69a5da"
      },
      "source": [
        "train = train_dataset\n",
        "tq = tqdm_notebook(range(EPOCHS))\n",
        "num_train_optimization_steps = int(EPOCHS*len(train)/batch_size/accumulation_steps)\n",
        "\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=lr)\n",
        "\n",
        "\n",
        "lossf=None\n",
        "loss_fn=nn.MSELoss()\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "for epochz in tq:\n",
        "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "    avg_loss = 0\n",
        "    avg_accuracy = 0\n",
        "    tk0= tqdm_notebook(enumerate(train_loader), total=len(train_loader),leave=False)\n",
        "    for i,(x_batch, y_batch) in tk0:\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            y_pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)[0]\n",
        "            loss = F.binary_cross_entropy_with_logits(y_pred,y_batch.to(device))\n",
        "        scaler.scale(loss).backward()\n",
        "        if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "        if lossf:\n",
        "            lossf = 0.98*lossf+0.02*loss.item()\n",
        "        else:\n",
        "            lossf = loss.item()\n",
        "\n",
        "        tk0.set_postfix(loss = lossf)\n",
        "        avg_loss += loss.item() / len(train_loader)\n",
        "        avg_accuracy += torch.mean(((torch.sigmoid(y_pred[:,0])>0.5) == (y_batch[:,0]>0.5).to(device)).to(torch.float) ).item()/len(train_loader)\n",
        "tq.set_postfix(avg_loss=avg_loss,avg_accuracy=avg_accuracy)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-63fe3cf6f4b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_train_optimization_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0maccumulation_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_grouped_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B-qwcbD5IaP"
      },
      "source": [
        "torch.save(model.state_dict(), 'bert_pytorch.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0vEnSMs5IaP"
      },
      "source": [
        "%%capture \n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=1).cuda()\n",
        "model.load_state_dict(torch.load('bert_pytorch.bin'))\n",
        "model.to(device)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "model.eval()  # print the model ---> you can remove \n",
        "val_batch_size = 128\n",
        "valid_preds = np.zeros((len(X_val)))\n",
        "valid = torch.utils.data.TensorDataset(torch.tensor(X_val,dtype=torch.long))\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=val_batch_size, shuffle=False)\n",
        "tk0 = tqdm_notebook(valid_loader)\n",
        "for i,(x_batch,)  in enumerate(tk0):\n",
        "    pred = model(x_batch.to(device), attention_mask=(x_batch>0).to(device), labels=None)[0]\n",
        "    valid_preds[i*val_batch_size:(i+1)*val_batch_size]=pred[:,0].detach().cpu().squeeze().numpy()\n",
        "    if i % 20 == 0:\n",
        "        print(\"batch: \", i, \" of \", len(valid_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLJA9HlQ5IaP"
      },
      "source": [
        "MODEL_NAME = 'model'\n",
        "test_df[MODEL_NAME]=torch.sigmoid(torch.tensor(valid_preds)).numpy()\n",
        "encode_column = 'encoding'\n",
        "bias_metrics_df = compute_bias_metrics_for_model(test_df, identity_columns, MODEL_NAME, 'encoding')\n",
        "bias_metrics_df\n",
        "get_final_metric(bias_metrics_df, calculate_overall_auc(test_df, MODEL_NAME))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}